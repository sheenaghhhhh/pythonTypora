# 1 内容回顾

```python
# 【一】网络编程
# 1.什么是网络编程
# 2.CS架构和BS架构
# 3.互联网的本质
# 4.OSI七层协议/TCP协议
# 5.以太网协议/Mac地址/广播/IP/子网掩码/网关/arp协议
# 以太网协议规定了局域网内不同设备之间进行交流的规范
# 世界范围的互联网用的是TCP/IP协议，我们需要在局域网内跨出去和其他的局域网进行交流
# 交流的媒介就是网关

# 6.Socket
# (1)基于TCP之上，应用层之间的抽象层
# (2)可以借助Socket实现客户端与服务端之间的通信而不需要关注底层原理
# (3)套接字编程
# 基于Socket进行网络编程
# a. 基于文件类型的套接字 AF_UNIX
# b. 基于网络类型的套接字 AF_INET
# (4)基于网路类型的套接字编程

# 7.TCP服务端和客户端交互
"""
# 1.服务端
import socket
# 创建服务端对象 SOCK_STREAM 流式协议
server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
# 绑定IP和端口
server.bind(('127.0.0.1', 8080))
# 创建半连接池
server.listen(5)
# 接收客户端的链接
conn, addr = server.accept()
# 接收客户端数据
conn.recv(1024)
# 发送给客户端数据
conn.send(b'hello')

# 2.客户端
# 创建客户端对象 SOCK_STREAM 流式协议
client = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
# 连接服务端 - 连接到目标的IP和端口
client.connect(('127.0.0.1', 8080))
# 发送给服务端数据
client.send(b'hello')
# 接收服务端的数据
client.recv(1024)
"""

# 8.UDP服务端和客户端交互
"""
# 1.服务端 
import socket
# 创建对象 SOCK_DGRAM报式协议
server = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
# 监听IP和端口
server.bind(('127.0.0.1', 8080))
# 接收客户端的数据
data, conn = server.recvfrom(1024)
# 发送给客户端数据
server.sendto(b'hello', conn)

# 2.客户端
# 创建客户端对象 SOCK_DGRAM 流式协议
client = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
# 发送给服务端数据
client.sendto(b'hello', ('127.0.0.1', 8080))
# 接收服务端的数据
client.recv(1024)
"""

# 9.粘包问题
# 粘包问题的必要条件
# 必须是TCP流式协议
# 数据方发送数据，一次发不完

# 粘包问题的解决方案
# 发送之前告诉对方数据量的大小 - 没办法打包数据的大小
# 修改接收方接受数据的大小 - 接收方的数据容量没办法自动扩容

# 使用struct+json模块打包数据信息
# (1)发送端
# 处理数据
# 用字典存储当前数据的所有详细信息 文件名,文件大小,md5哈希值
# 利用json模块将当前数据转为json字符串,将json字符串再转为二进制数据
# 计算json二进制数据的长度 使用struct模块将当前数据大小转为二进制数据(利用i模式将任意数据打包成4个字节的二进制数据)

# 发送数据
# 先发送四个字节的 struct 打包后的数据
# json二进制数据
# 原始二进制数据

# (2)接收端
# 接收 四个字节的二进制数据 -> struct 打包后的四个字节的二进制数 json二进制数据的长度
# 接收 json二进制数据 用json模块把json二进制数据转回字典
# 字典取出当前数据的总长度
# 根据总长度迭代 将所有数据接收到

# 为什么 能迭代获取到所有的二进制数据
# TCP是流式协议，数据一直在就一直接收
# TCP四次挥手的第二次挥手

# 10.TCP三次握手
# 第一次握手: 客户端发起,携带客户端标识和建立连接标识 发送给服务端
# 第二次握手: 服务端发起,携带服务端标识和建立连接标识以及目标客户端的标识 发送给目标客户端的标识
# 第三次握手: 客户端发起,携带客户端标识和建立连接标识以及目标服务端的标识

# 11.TCP四次挥手
# 第一次挥手: 客户端发起,携带客户端标识和断开连接标识 发送给服务端
# 第二次挥手: 服务端发起,携带服务端标识和数据未处理完成后不能断开连接标识以及目标客户端标识 发送给目标客户端
# 第三次挥手: 服务端发起,携带服务端标识和断开连接标识以及目标客户端标识 发送给目标客户端
# 第四次挥手: 客户端发起,携带客户端标识和断开连接标识以及目标服务端的标识

# 12.并发编程
# (1)操作系统
# 用来操作底层硬件封装后的接口
# (2)多路复用
# 时间上的复用：谁占用的时间长就分配给谁权限使用
# 空间上的复用：谁占用的资源多就给谁分配资源
# (3)操作系统的发展史
# 第一代计算机：真空管和穿孔卡片
# 第二代计算机：晶体管和批处理系统
# 第三代计算机：集成电路芯片和多道程序设计
# 第四代计算机：现在使用的计算机
# (4)多进程理论
# 程序是存储在电脑硬盘上的数据
# 进程是在电脑上的运行实例
# (5)进程调度算法
# 先来先服务
# 短作业优先
# 时间片轮转
# 多级反馈队列
# (6)并发与并行
# 并发：多个任务交替进行，伪并行
# 并行：多个任务同时进行，依赖于多核CPU和多道技术
# (7)同步与异步
# 同步：一个进程启动后，只有获取到当前进程的结果才能进行下一个进程
# 异步：一个进程启动后，不需要等待当前进程的结果就能进行下一个进程
# 针对的是进程的调用方式
# (8)阻塞与非阻塞
# 阻塞指当前进程遇到系统调用或者网络调用时会进入阻塞状态
# 非阻塞指当前进程遇到系统调用或者网络调用时不会进入阻塞状态
# 针对的是进程运行的状态
# (9)进程的创建和终止
# 进程的创建方式：
# 系统初始化
# 主进程中开启子进程
# 交互式请求
# 批作业处理
# 进程的终止：
# 正常终止
# 出错退出
# 严重错误退出
# 被其他进程杀死 kill / taskkill
# (10)进程的状态
# 五态模型：
# 创建 就绪 阻塞 运行 终止
# 三态模型：
# 运行 阻塞 就绪
```

```python
# 借助内置模块

# 【一】创建多进程的两种方式
"""
import multiprocessing


# 1.方式一 实例化Process
def work():
    ...


def process():
    task_list = []
    for i in range(5):
        task = multiprocessing.Process(
            target=work,
            args=(),
            kwargs={},
            daemon=False
        )
        task.start()
        task_list.append(task)
    [task.join() for task in task_list]


# 2.方式二进程Process重写run
class MyProcess(multiprocessing.Process):
    def run(self):
        ...


def my_process():
    task_list = []
    for i in range(5):
        task = MyProcess()
        task.start()
        task_list.append(task)
    [task.join() for task in task_list]
"""

# 注意：要在main入口下启动多进程


# 【二】多进程的属性和方法
"""
task = multiprocessing.Process()
task.start()  # 启动子进程 --- 触发的就是 run 方法
task.join()  # 阻塞子进程
task.terminate()  # 杀死当前子进程
task.kill()  # 杀死子进程
task.run() # 直接启动子进程
task.is_alive() #  判断当前子进程是否在活着

task.daemon # 当前子进程是否是守护进程
task.pid # 获取当前子进程的进程号
task.name # 获取当前子进程的名字
task.exitcode # 获取当前子进程的终止码
"""

# 【三】进程间通信
# IPC Inter Process Communication
# 进程间进行信息交流就叫进程间通信
# 进程间通信的两种方式：队列 管道

# 1.队列
# (1)队列模块 Queue
"""
import queue

# 得到一个队列对象 maxsize 当前队列的最大容量
queue = queue.Queue(maxsize=10)
# 向队列中添加数据 timeout 超时时间,超出指定时间没有就会抛出异常
queue.put(1, timeout=5)
# 从队列中获取数据 timeout同上
queue.get(timeout=5)

queue.get_nowait()
queue.full()
queue.empty()
"""

# (2)使用进程模块提供的队列模块
from multiprocessing import Queue
# 方法和上面一致
# 先生成队列对象 给子进程用
# 子进程向队列中添加数据
# 子进程或主进程可以从队列中拿出数据

# 一旦消费者高于生产者 生产者生产的数据过少 导致消费者一直获取不到数据 导致阻塞
# 为解决上述问题 在生产者生产结束后再加一个结束标志

# 多进程模块提供了一种方案
# 使用JoinableQueue 代替原来的队列模块
from multiprocessing import JoinableQueue
# 内置 join - 在生产者生产结束后增加标志
# 内置 task_done - 从队列中动态获取当前队列的总数据

# 2.管道
# 管道是双向的，所以在使用的时候
# 要关闭一侧管道，打开另一侧
# 使用多进程提供的管道
from multiprocessing import Pipe

left_conn, right_conn = Pipe()

# 【三】僵尸进程和孤儿进程
# 1.僵尸进程
# 子进程未正常结束，本来应该将当前子进程占用的资源筛掉
# 但是没有被正常释放，导致当前资源一直被占用

# 2.孤儿进程
# 主进程提前结束，但子进程没有人管，init会接管这个子进程
# 帮助当前子进程

# 3.僵尸进程危害性更大
# 大量占用当前资源
# 资源被占用完毕 系统会崩溃

# 4.解决僵尸进程
# 方式一：在启动子进程之后加join阻塞进程 (join会帮助我们自动杀死僵尸进程)
# 方式二：手动杀死子进程所在的主进程/子进程

# 【四】守护进程
# 守护进程是系统启动之后就会一直存在的进程
# 随着系统的启动而启动，随着系统的结束而结束

# 多进程来说：子进程随着主进程存活而存活，一旦主进程死亡就会死亡

# 增加守护进程的方式：
# 在子进程启动之前 + task.daemon = True
```



# 2 多线程理论

```python
# 【一】什么是线程
# 传统的操作系统中，每一个进程都是有一块内存空间地址，默认在一个进程下是有一个线程
# 在一个进程下开设多个进程 开设的多个进程叫线程
# 在一条流水线上
# 一条流水线就是一个车间 车间就是一个进程
# 车间里面又有很多工位 每个工位就是一个线程

# 多线程：一个进程中存在多个控制线程 多个控制线程共享当前进程的资源

# 进程是操作系统的资源分配的最小单位
# 线程是CPU调度执行的最小单位


# 【二】线程的创建开销和进程的创建开销谁更大
# 进程创建开销大
# 每一个进程都要划分走内存中的一块地址，并且相互独立
# 线程开设在已经分配好的内存空间地址内

# 【三】为什么要有多线程
# 1.开设进程消耗的资源多且复杂
# 开设线程占用的资源少

# 2.一个进程内可以开设多个线程，在开设线程的时候不需要申请内存空间和拷贝数据

# 3.减少资源耗时
```



# 3 多线程操作

```python
# 【一】多线程借助内置模块
# 多进程
import random
import time
from multiprocessing import Process
# 多线程
from threading import Thread


def timer(func):
    def inner(*args, **kwargs):
        start_time = time.time()
        func(*args, **kwargs)
        end_time = time.time()
        print(f"{func.__name__} took {end_time - start_time} time")

    return inner


# 【二】开设多线程的两种方式
# 1.process类
def work(name):
    sleep_time = random.randint(1, 6)
    print(f"{name} is starting sleeping {sleep_time}")
    time.sleep(sleep_time)
    print(f"{name} is ending.")


@timer
def process_work():
    task_list = [Process(target=work, args=(i,)) for i in range(4)]
    [task.start() for task in task_list]
    [task.join() for task in task_list]


# 2.继承Process类并重写run方法
class MyProcess(Process):
    def __init__(self, input_name):
        super().__init__()
        self.input_name = input_name

    def run(self):
        sleep_time = random.randint(1, 6)
        print(f"{self.name} is starting sleeping {sleep_time}")
        time.sleep(sleep_time)
        print(f"{self.name} is ending.")


@timer
def my_process():
    task_list = [MyProcess(input_name=i) for i in range(5)]
    # 将每一个子进程启动
    [task.start() for task in task_list]
    # 阻塞每一个子进程
    [task.join() for task in task_list]


# 【三】多线程的两种方式
# 1.Thread类
def work_thread(name):
    sleep_time = random.randint(1, 6)
    print(f"{name} is start sleeping  {sleep_time}")
    time.sleep(sleep_time)
    print(f"{name} is end sleeping ")


@timer
def process_thread_work():
    task_list = [Thread(target=work_thread, args=(i,)) for i in range(4)]
    # 将每一个子进程启动
    [task.start() for task in task_list]
    # 阻塞每一个子进程
    [task.join() for task in task_list]


# 2.继承Thread类 重写run 法
class MyThread(Thread):
    def __init__(self, input_name):
        super().__init__()
        self.name = input_name

    def run(self):
        sleep_time = random.randint(1, 6)
        print(f"{self.name} is start sleeping  {sleep_time}")
        time.sleep(sleep_time)
        print(f"{self.name} is end sleeping ")


@timer
def my_process_thread():
    task_list = [MyThread(input_name=i) for i in range(5)]
    # 将每一个子进程启动
    [task.start() for task in task_list]
    # 阻塞每一个子进程
    [task.join() for task in task_list]


if __name__ == '__main__':
    print(f"main process start .... ")
    # process_thread_work()
    my_process_thread()
    print(f"main process end .... ")
# 像进程一样
# 一个是定义Thread对象
# 一个是重写Thread类 重写run方法
```



# 4 多线程属性

```python
import os
import random
import time
from threading import Thread


def timer(func):
    def inner(*args, **kwargs):
        start_time = time.time()
        func(*args, **kwargs)
        end_time = time.time()
        print(f"{func.__name__} 运行时间：{end_time - start_time}")

    return inner


def work_thread(name):
    # 查看当前进程下的进程号 ：current_process().pid
    # from multiprocessing import current_process
    # 借助 os 模块 ： os.getpid()
    # 获取当前线程的线程号
    from threading import current_thread, active_count
    # 获取当前子线程的名字 current_thread().name
    # 统计当前存活的线程数
    sleep_time = random.randint(1, 6)
    print(f"{name} {os.getpid()} {current_thread().name} {active_count()} is start sleeping  {sleep_time}")
    time.sleep(sleep_time)
    print(f"{name} {os.getpid()}  {current_thread().name} {active_count()} is end sleeping ")


@timer
def process_thread_work():
    task_list = []
    # for i in range(4):
    #     task = Thread(target=work_thread, args=(i,))
    #     task_list.append(task)
    task_list = [Thread(target=work_thread, args=(1,))]
    # 将每一个子进程启动
    [task.start() for task in task_list]
    # 阻塞每一个子进程
    [task.join() for task in task_list]


if __name__ == '__main__':
    process_thread_work()
    # 每一个子线程的进程号一致：印证了所有的子线程都是同一个进程开设的

    # 0 7558 Thread-1 (work_thread) 2 is start sleeping  5
    # 在第一次启动子线程（只有一个子线程的时候打印的线程存活数是2 是为什么？）
    # 每一个进程开启的时候都会自带一个主线程

    # print(random.randint(1, 11))
```



# 5 多线程实现TCP服务器并发

```python
# server


from socket import socket, AF_INET, SOCK_STREAM, SOL_SOCKET, SO_REUSEADDR
from threading import Thread


def work(conn, addr):
    while True:
        data_from_client = conn.recv(1024)
        print(f"来自客户端 {addr} 的数据 :>>>> {data_from_client.decode()}")
        # 返回数据
        conn.send(data_from_client.decode().upper().encode())


def multy_process(cls, conn, addr):
    task = cls(target=work, args=(conn, addr))
    task.start()


def main():
    server = socket(AF_INET, SOCK_STREAM)

    server.setsockopt(SOL_SOCKET, SO_REUSEADDR, 1)

    server.bind(("127.0.0.1", 9690))

    server.listen(5)

    while True:
        conn, addr = server.accept()
        # 开设多进程
        # multy_process(cls=Process, conn=conn, addr=addr)
        multy_process(cls=Thread, conn=conn, addr=addr)


if __name__ == '__main__':
    main()
```

```python
# client


from socket import socket, AF_INET, SOCK_STREAM

client = socket(AF_INET, SOCK_STREAM)

client.connect(('127.0.0.1', 9690))

while True:
    send_data = input("请输入 :>>>> ").strip()

    client.send(send_data.encode('utf-8'))

    recv_data = client.recv(1024)

    print(f"当前返回数据 :>>>> {recv_data.decode()}")
```





# 6 互斥锁

## 6.1 理论

```python
# ● 互斥锁（Mutex）是一种用于多线程编程中控制对共享资源访问的机制。
#   ○ 其作用是保证在同一时刻只有一个线程在访问共享资源，从而避免多个线程同时读写数据造成的问题。
#   ○ 互斥锁的基本原理是在对共享资源进行访问前加锁，使得其他线程无法访问该资源，当访问完成后再解锁，使得其他线程可以进行访问。
#   ○ 通过这种方式，可以保证同一时间只有一个线程在执行关键代码段，从而保证了数据的安全性。
#   ○ 需要注意的是，互斥锁会带来一些额外的开销，


# 互斥锁是为了解决子线程之间共享冲突问题
# 但在多进程下也有这个问题 -> 其他语言没有这个问题
```

## 6.2 进程间共享终端打印

```python
import json
import os
import random
import time
from multiprocessing import Process, Lock
from threading import Thread


def timer(func):
    def inner(*args, **kwargs):
        start_time = time.time()
        func(*args, **kwargs)
        end_time = time.time()
        print(f"{func.__name__} 运行时间：{end_time - start_time}")

    return inner


def work_thread(name, lock):
    # 在发生数据改变之前进行加锁
    lock.acquire()

    from threading import current_thread, active_count
    sleep_time = random.randint(1, 6)
    print(f"{name} {os.getpid()} {current_thread().name} {active_count()} is start sleeping  {sleep_time}")
    time.sleep(sleep_time)
    print(f"{name} {os.getpid()}  {current_thread().name} {active_count()} is end sleeping ")

    # 在使用时候释放当前锁
    lock.release()


@timer
def process_work(cls):
    # 生成锁对象
    lock = Lock()
    task_list = []
    for i in range(4):
        task = cls(target=work_thread, args=(i, lock))
        task_list.append(task)
    # 将每一个子进程启动
    [task.start() for task in task_list]
    # 阻塞每一个子进程
    [task.join() for task in task_list]


def process_thread():
    print(f"main process start ... ")
    process_work(cls=Thread)
    print(f"main process end ... ")


# 在加锁的时候应该是数据发生改变的位置加锁
# 加锁之后的多进程就变成了 串行
def process_process():
    print(f"main process start ... ")
    process_work(cls=Process)
    print(f"main process end ... ")
```

## 6.3 抢票问题

```python
# 将票数据存放在本地的文件中
db_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), "ticket.json")


def init_data():
    data = {"ticket_number": 2}
    save_data(data)
    print(f"初始化完成")


# 保存票数据
def save_data(data):
    with open(db_path, "w") as fp:
        json.dump(data, fp)


# 获取票数据
def read_data():
    with open(db_path, "r") as fp:
        data = json.load(fp)
    return data


# 1.查看有哪些票
def search_ticket(username):
    ticket_data = read_data()
    print(f"当前 {username} 查看票， 票剩余: {ticket_data.get('ticket_number')}")


# 2.买票
def buy_ticket(user_name):
    # 先查询票
    ticket_data = read_data()
    print(f"当前 {user_name} 查看票数，余票 :>>> {ticket_data.get('ticket_number')}")

    # 增加延迟 模拟买票时的网络延迟
    time.sleep(random.randint(1, 3))
    # 获取数据库中的总票数
    ticket_number = ticket_data.get('ticket_number')
    if ticket_number > 0:
        ticket_data['ticket_number'] -= 1
        save_data(ticket_data)
        print(f"{user_name}购票成功! 余票:>>> {ticket_data.get('ticket_number')}")
    # 无票告诉没有票
    else:
        print(f"票数不足")


def process_multy():
    task_list = [Process(target=buy_ticket, args=(f"用户{i}",)) for i in range(1, 5)]
    [task.start() for task in task_list]
    [task.join() for task in task_list]
```

## 6.4 抢票问题 加锁

```python
def buy_ticket_lock(user_name, lock):
    ticket_data = read_data()
    # 增加延迟
    time.sleep(random.randint(1, 3))

    ticket_number = ticket_data.get('ticket_number')
    if ticket_number > 0:
        ticket_data['ticket_number'] -= 1
        save_data(ticket_data)
        print(f"{user_name}购票成功! 余票:>>> {ticket_data.get('ticket_number')}")
    # 无票告诉没有票
    else:
        print(f"票数不足")


def process_multy_lock():
    # 得到一把锁
    lock = Lock()
    task_list = []  # 生成5个子进程
    for i in range(1, 6):
        task = Process(target=main_process, args=(f"用户{i}", lock))
        task.start()
        task_list.append(task)
    [task.join() for task in task_list]


def main_process(user_name, lock):
    search_ticket(username=user_name)

    # 在数据改变之前加锁
    lock.acquire()
    buy_ticket_lock(user_name, lock)
    # 买完释放
    lock.release()


if __name__ == "__main__":
    init_data()
    """
    process_multy():
    当前 用户2 查看票数，余票 :>>> 2
    当前 用户1 查看票数，余票 :>>> 2
    当前 用户3 查看票数，余票 :>>> 2
    当前 用户4 查看票数，余票 :>>> 2
    用户3购票成功! 余票:>>> 1
    用户2购票成功! 余票:>>> 1
    用户1购票成功! 余票:>>> 1
    用户4购票成功! 余票:>>> 1
    """
    process_multy_lock()
    """
    当前 用户1 查看票， 票剩余: 2
    当前 用户2 查看票， 票剩余: 2
    当前 用户4 查看票， 票剩余: 2
    当前 用户3 查看票， 票剩余: 2
    当前 用户5 查看票， 票剩余: 2
    用户1购票成功! 余票:>>> 1
    用户2购票成功! 余票:>>> 0
    票数不足
    票数不足
    票数不足
    """
```



# 7 线程互斥锁

```python
import random
import time
from multiprocessing import Process
from threading import Thread, Lock

money = 99


def work(name, lock):
    global money

    lock.acquire()
    # 用临时变量存起来
    temp = money
    # 模拟延迟
    time.sleep(0.6)
    print(f"{name} 改之前 ::>> temp {temp} | money {money}")
    money = temp - 1
    print(f"{name} 改之后 ::>> temp {temp} | money {money}")

    lock.release()


def process(cls):
    # 【获取锁】
    lock = Lock()
    print(f"修改之前 :>>>> {money}")

    task_list = [cls(target=work, args=(i, lock)) for i in range(99)]
    [task.start() for task in task_list]
    [task.join() for task in task_list]

    print(f"修改之后 :>>>> {money}")


if __name__ == '__main__':
    # process(Process) # 99
    process(Thread)  # 0

# 核心：为了避免多个线程或进程之间对同一个读写数据错乱的问题
# 我们需要在改之前枷锁 ，改之后解锁
# 由原本的并行改为了串行

# 但是为了数据安全这是最好的办法
```